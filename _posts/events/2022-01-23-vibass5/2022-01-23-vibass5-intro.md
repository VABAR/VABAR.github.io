---
layout: page
title: "VIBASS5 - Basic Course"
subheadline: "Introduction to Bayesian Learning"
meta_teaser: "VIBASS5 Basic Course"
teaser: VIBASS5 Basic Course
header:
  title: VIBASS 5
  image_fullwidth: header_vibass18.png
  caption: Registration form
image:
  thumb: widget_vibass5.png
  homepage: vibass5.jpg
categories: events
---

The first two days include a basic course on Bayesian learning (12
hours), with conceptual sessions in the morning and practical sessions
with basic Bayesian packages in the afternoon. This is a summary of the
contents of both days.

## Monday

### Session I: __All you need is... probability__

Frequentist and Bayesian probability. Bayesâ€™ theorem for random events and variables,
parameters, hypothesis, etc. Sequential updating. Predictive probabilities.

### Session II: __Binary data__

__Proportions__: binomial distribution and likelihood function.
__Prior distribution__: the beta distribution.
__Summarising__ posterior inferences.


### Session III. __Inference and prediction with simulated samples__

__Estimation and prediction__. Simulated samples: comparison of independent populations.

### Session IV. __Count data__

__Count data__: Poisson distribution. Poisson model parameterized in terms of rate and exposure. Gamma distribution as __conjugate prior distributions__. Negative binomial __predictive distributions__. 


### Session V. Normal data.

__Normal data__: Estimation of a normal mean with known variance. __Prediction__ of a future observation. Normal data with unknown mean and variance. __Nuisance
parameters__. __Joint prior distributions__. Joint, conditional and marginal
__posterior distributions__. 


## Tuesday

### Session I: All you need is... modelling

The big problem in the Bayesian framework: resolution of integrals that appear when applying the learning process.


### Session II. Numerical approaches to the posterior distribution.

__Numerical approaches__: Gaussian approximations, Laplace approximations, Monte Carlo integration and importance sampling. __Markov chain Monte Carlo__: Gibbs sampling and Metropolis Hastings. Convergence, inspection of chains,
etc. 

### Session III. Software for Bayesian Analysis

__Software__ for inference in Bayesian hierarchical models.


### Session IV. Bayesian hierarchical models

Incorporating _random_ effects: __Bayesian hierarchical models__ (BHMs), the coolest tool for modelling highly structured models. Hierarchies, hyperparameters, and hyperpriors. (Generalized) linear mixed models as basic examples of BHMs.
