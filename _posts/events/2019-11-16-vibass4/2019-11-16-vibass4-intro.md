---
layout: page
title: "VIBASS4 - Basic Course"
subheadline: "Introduction to Bayesian Learning"
meta_teaser: "VIBASS4 Basic Course"
teaser: VIBASS4 Basic Course
header:
  title: VIBASS 4
  image_fullwidth: header_vibass18.png
  caption: Registration form
image:
  thumb: widget_vibass4.png
  homepage: vibass4.jpg
categories: events
---

The first two days include a basic course on Bayesian learning (12
hours), with conceptual sessions in the morning and practical sessions
with basic Bayesian packages in the afternoon. This is a summary of the
contents of both days.

## Monday

### Session I: __All you need is... probability__

- Introductory session: 09:30 -- 10:00

Frequentist and Bayesian probability. Bayesâ€™ theorem for random events and variables,
parameters, hypothesis, etc. Sequential updating. Predictive probabilities.

### Session II: __Binary data__

- Theory: 10:10 -- 10:40
- Practice: 10:50 -- 11:50

__Proportions__: binomial distribution and likelihood function.
__Prior distribution__: the beta distribution.
__Summarising__ posterior inferences.

### Session III. __Count data__

- Theory: 12.10 -- 12.30
- Practice: 12.45 -- 13.30

__Count data__: Poisson distribution. Poisson model parameterized in terms of rate and exposure. Gamma distribution as __conjugate prior distributions__. Negative binomial __predictive distributions__. 


### Session IV. Normal data.
- Theory: 15.00 -- 15.30
- Practice: 15.40 -- 16.30

__Normal data__: Estimation of a normal mean with known variance. __Prediction__ of a future observation. Normal data with unknown mean and variance. __Nuisance
parameters__. __Joint prior distributions__. Joint, conditional and marginal
__posterior distributions__. 


### Session V. Inference and prediction with simulated samples.
- Theory: 16.45 -- 17.15
- Practice: 17.30 -- 18.30

__Estimation and prediction__. Simulated samples: comparison of independent populations.

## Tuesday

### Session I: All you need is... modelling

- Theory: 09.30 -- 10.00
- Practice: 10.10 -- 10.50

The big problem in the Bayesian framework: resolution of integrals that appear when applying the learning process.


### Session II. Numerical approaches to the posterior distribution.

- Theory: 11.00 -- 11.30
- Practice: 11.40 -- 12.30

__Numerical approaches__: Gaussian approximations, Laplace approximations, Monte Carlo integration and importance sampling. __Markov chain Monte Carlo__: Gibbs sampling and Metropolis Hastings. Convergence, inspection of chains,
etc. 

### Session III. Bayes software

- Theory: 13.00 -- 13.30
- Practice: 15.00 -- 15.40

__Software__ for inference in Bayesian hierarchical models.


### Session IV. Bayesian hierarchical models

- Theory: 15.50 -- 16.30
- Practice 1: 16.45 -- 17.35
- Practice 2: 17.55 -- 18.30

Incorporating _random_ effects: __Bayesian hierarchical models__ (BHMs), the coolest tool for modelling highly structured models. Hierarchies, hyperparameters, and hyperpriors. (Generalized) linear mixed models as basic examples of BHMs.
